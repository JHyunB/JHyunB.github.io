<!DOCTYPE html><html lang="en-us"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><title>MNIST | BaekJongHyun</title><meta name="description" content="MNIST"><meta name="generator" content="BaekJongHyun"><meta name="author" content="John Doe"><meta name="keywords"><meta name="HandheldFriendly" content="True"><meta name="MobileOptimized" content="320"><meta name="viewport" content="width=device-width,initial-scale=1.0,maximum-scale=1,user-scalable=0"><link rel="stylesheet" type="text/css" href="/styles/screen.css"><link rel="apple-touch-icon" sizes="57x57" href="/images/apple-touch-icon-57x57.png"><link rel="apple-touch-icon" sizes="60x60" href="/images/apple-touch-icon-60x60.png"><link rel="apple-touch-icon" sizes="72x72" href="/images/apple-touch-icon-72x72.png"><link rel="apple-touch-icon" sizes="76x76" href="/images/apple-touch-icon-76x76.png"><link rel="apple-touch-icon" sizes="114x114" href="/images/apple-touch-icon-114x114.png"><link rel="apple-touch-icon" sizes="120x120" href="/images/apple-touch-icon-120x120.png"><link rel="apple-touch-icon" sizes="144x144" href="/images/apple-touch-icon-144x144.png"><link rel="apple-touch-icon" sizes="152x152" href="/images/apple-touch-icon-152x152.png"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-180x180.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png"><link rel="icon" type="image/png" sizes="96x96" href="/images/favicon-96x96.png"><link rel="icon" type="image/png" sizes="128x128" href="/images/favicon-128.png"><link rel="icon" type="image/png" sizes="196x196" href="/images/favicon-196x196.png"><meta name="msapplication-TileColor" content="#FFFFFF"><meta name="msapplication-TileImage" content="mstile-144x144.png"><meta name="msapplication-square70x70logo" content="mstile-70x70.png"><meta name="msapplication-square150x150logo" content="mstile-150x150.png"><meta name="msapplication-wide310x150logo" content="mstile-310x150.png"><meta name="msapplication-square310x310logo" content="mstile-310x310.png"><link rel="stylesheet" href="/css/prism.css" type="text/css"></head><body itemscope itemtype="https://schema.org/WebPage"><header itemscope itemtype="https://schema.org/WPHeader"><div class="logo"></div><h1><a href="/" alt="BaekJongHyun" title="BaekJongHyun" itemprop="headline">BaekJongHyun</a></h1><p itemprop="description"></p><nav itemscope itemtype="https://schema.org/SiteNavigationElement"><ul><li itemprop="name"><a href="/ " alt="home" title="home" itemprop="url">home</a></li><li itemprop="name"><a href="/articles" alt="articles" title="articles" itemprop="url">articles</a></li><li itemprop="name"><a href="/author" alt="author" title="author" itemprop="url">author</a></li></ul></nav><div class="space"></div></header><main itemscope itemtype="https://schema.org/Blog"><article class="full"><h1 itemprop="headline" class="post-heading">MNIST</h1><span class="page-tag-anchor"><a href="/tags/MNIST" itemprop="url">#MNIST
&nbsp;&nbsp;</a></span><span class="page-tag-anchor"><a href="/tags/머신러닝" itemprop="url">#머신러닝
&nbsp;&nbsp;</a></span><span class="page-tag-anchor"><a href="/tags/기초" itemprop="url">#기초
&nbsp;&nbsp;</a></span><span class="post-meta"></span><br><br><h1 id="MNIST"><a href="#MNIST" class="headerlink" title="MNIST"></a>MNIST</h1><h3 id="1-데이터-불러오기"><a href="#1-데이터-불러오기" class="headerlink" title="1. 데이터 불러오기"></a>1. 데이터 불러오기</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data  <span class="comment">#tensorflow샘플에 포함된 예제</span></span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">"MNIST_data/"</span>, one_hot=<span class="literal">True</span>)  <span class="comment">#학습데이터 다운로드</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br></pre></td></tr></table></figure>
<ul>
<li>55000개의 학습 데이터(mnist.train)</li>
<li>10000개의 테스트 데이터(mnist.test)</li>
<li>5000개의 검증 데이터(mnist.validation)</li>
<li>데이터 = xs(이미지) + xy(라벨)</li>
</ul>
<p>ex) 학습세트의 이미지 : mnist.train.images</p>
<p>​      학습세트의 라벨 : mnist.train.labels</p>
<ul>
<li>one-hot 벡터는 하나의 차원만 1이고 나머지 모든 차원들은 0으로 채워진 벡터이다.</li>
</ul>
<p>ex) 3 -&gt; [0,0,0,1,0,0,0,0,0,0]</p>
<p>데이터 갯수가 늘어날수록 벡터의 크기가 계속 늘어나기 때문에 데이터가 많을경우 비효율적이다.</p>
<hr>
<h3 id="2-변수-설정하기"><a href="#2-변수-설정하기" class="headerlink" title="2. 변수  설정하기"></a>2. 변수  설정하기</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">784</span>]) <span class="comment"># None은 어떤 길이도 될수 있음, 28X28 pixel</span></span><br><span class="line">W = tf.Variable(tf.zeros([<span class="number">784</span>, <span class="number">10</span>]))  <span class="comment"># 가중치값 변수, 10 : 0~9</span></span><br><span class="line">b = tf.Variable(tf.zeros([<span class="number">10</span>]))  <span class="comment"># 편향값 변수</span></span><br><span class="line">y = tf.nn.softmax(tf.matmul(x, W) + b)  <span class="comment"># matmul 곱하기, 소프트맥스 회귀로 모델 만들기</span></span><br></pre></td></tr></table></figure>
<p><img src="https://user-images.githubusercontent.com/36959292/55800852-9c835300-5b0f-11e9-868e-0214a36b752a.png" alt="softmax-evidence"></p>
<ul>
<li>소프트맥스 방식: 입력이 특정 클래스에 해당되는지 증거를 더하고, 증거를 확률로 변환</li>
</ul>
<p>증거 계산을 위해서 픽셀 농도의 가중치합을 이용한다.</p>
<p><img src="https://user-images.githubusercontent.com/36959292/55801000-04399e00-5b10-11e9-936d-ebdcc05dd35e.png" alt="softmax"> </p>
<p>빨간색은 음수, 파란색은 양수 가중치를 갖는다.</p>
<ul>
<li>입력값을 0~1사이의 값으로 정규화 하여 출력한다. 출력값의 합은 항상 1이다.</li>
</ul>
<p>ex) (0.9, 0.8, 0.7)가 절댓값은 높지만 (0.6, 0.3, 0.1)이 구분하기 쉽다.</p>
<hr>
<h3 id="3-cross-entrophy"><a href="#3-cross-entrophy" class="headerlink" title="3. cross-entrophy"></a>3. cross-entrophy</h3><p>모델을 학습시킬때, 무엇이 좋은지 나쁜지 정의가 필요하다.<br>비용(cost) 또는 소실(loss)을 최소화 하려고 시도하는데 괜찮은 비용함수 중 하나가 cross-entropy이다.<br>이 값이 낮을수록 좋은 모델이다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y_ = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">10</span>])  <span class="comment"># 새 placeholder 추가, 숫자 0~9</span></span><br><span class="line">cross_entropy = -tf.reduce_sum(y_ * tf.log(y))  <span class="comment"># 모든 차원이 제거되고 하나의 스칼라 값</span></span><br></pre></td></tr></table></figure>
<p><img src="https://user-images.githubusercontent.com/36959292/55802404-2123a080-5b13-11e9-9ead-fb04c3f664ce.png" alt="cross-entrophy"></p>
<p>tensorflow는 계산과정의 전체 그래프를 알고 있어, 비용 최소화에 어떤 변수가 얼마나 영향을 주는지 효율적으로 계산한다. cross-entropy(비효율정도)를 최소화하는 방향으로 최적화 하는 방법은 여러가지가 있지만 여기서는<br>경사하강법(gradient descent)을 이용한다. </p>
<p><img src="https://user-images.githubusercontent.com/36959292/55803668-bfb10100-5b15-11e9-84d6-84da18bb47cf.png" alt="gradientdecent"></p>
<p>손실을 줄이기위해 함수의 그래프상(y축 손실) 최소값을 찾기위해 기울기의 반대방향으로 이동한다.<br>학습도(tensor or floating point value)를 0.01주고 경사하강법알고리즘을 이용하여 교차 엔트로피를 최소화한다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_step = tf.train.GradientDescentOptimizer(<span class="number">0.01</span>).minimize(cross_entropy)</span><br></pre></td></tr></table></figure>
<p>이제 학습을 위한 모델의 준비가 끝났다.</p>
<hr>
<h3 id="4-학습시키기"><a href="#4-학습시키기" class="headerlink" title="4. 학습시키기"></a>4. 학습시키기</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 만든 변수들을 초기화하고 세션에서 모델을 시작한다.</span></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">sess = tf.Session()</span><br><span class="line">sess.run(init)</span><br><span class="line"><span class="comment"># 1000번을 학습시킨다.</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">  batch_xs, batch_ys = mnist.train.next_batch(<span class="number">100</span>)  <span class="comment"># 학습세트에서 100개의 무작위 데이터들을  가져옴</span></span><br><span class="line">  sess.run(train_step, feed_dict=&#123;x: batch_xs, y_: batch_ys&#125;)  <span class="comment"># 이미지, 라벨</span></span><br></pre></td></tr></table></figure>
<hr>
<h3 id="5-평가하기"><a href="#5-평가하기" class="headerlink" title="5. 평가하기"></a>5. 평가하기</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">correct_prediction = tf.equal(tf.argmax(y, <span class="number">1</span>), tf.argmax(y_, <span class="number">1</span>))  <span class="comment">#실제와 맞았는지?</span></span><br><span class="line">accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))  <span class="comment">#  타입 캐스트하고, 모든 차원이 제거되고 하나의 스칼라값 평균</span></span><br><span class="line">print(sess.run(accuracy, feed_dict=&#123;x: mnist.test.images, y_: mnist.test.labels&#125;))  <span class="comment"># 테스트 이미지와 라벨을 넣고 정확도 테스트</span></span><br></pre></td></tr></table></figure>
<ul>
<li>tf.argmax() : 가장 큰 원소의 인덱스</li>
</ul>
<hr>
<h3 id="6-참고"><a href="#6-참고" class="headerlink" title="6. 참고"></a>6. 참고</h3><p><a href="https://bcho.tistory.com/1154" target="_blank" rel="noopener">https://bcho.tistory.com/1154</a></p>
<p><a href="https://codeonweb.com/entry/12045839-0aa9-4bad-8c7e-336b89401e10" target="_blank" rel="noopener">https://codeonweb.com/entry/12045839-0aa9-4bad-8c7e-336b89401e10</a></p>
<p> <a href="https://www.tensorflow.org/tutorials/mnist/beginners/" target="_blank" rel="noopener">https://www.tensorflow.org/tutorials/mnist/beginners/</a></p>
</article><br><br><span class="next-post"><a href="/2019/04/03/makeBlog/" itemprop="url">Older Post ⇒</a></span><br><section id="comments"><h2>Comments<div id="disqus_thread"><noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus</a>.</noscript></div></h2></section><br><br></main><script async>(function(h,g,l,k,j,i){j=h.createElement(g),i=h.getElementsByTagName(g)[0],
j.src = '//' + l + '.disqus.com/' + k + '.js', i.parentNode.insertBefore(j, i)})
(document,'script','JHyunB','embed');
</script><script async>var disqus_shortname = 'JHyunB';
(function () {
var s = document.createElement('script'); s.async = true;
s.type = 'text/javascript';
s.src = '//' + disqus_shortname + '.disqus.com/count.js';
(document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(s);
}());
</script></body></html>